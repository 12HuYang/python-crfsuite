{
 "metadata": {
  "name": "",
  "signature": "sha256:4aecb99dbf186c82eff39626bd2b30a911e50a688f5cdadf0a92363848ec8c50"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import chain\n",
      "import nltk\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.preprocessing import LabelBinarizer\n",
      "import pycrfsuite"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Let's use CoNLL 2002 data to build a NER system\n",
      "\n",
      "CoNLL2002 corpus is available in NLTK. We use Spanish data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.corpus.conll2002.fileids()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "['esp.testa', 'esp.testb', 'esp.train', 'ned.testa', 'ned.testb', 'ned.train']"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "train_sents = list(nltk.corpus.conll2002.iob_sents('esp.train'))\n",
      "test_sents = list(nltk.corpus.conll2002.iob_sents('esp.testb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 4.35 s, sys: 169 ms, total: 4.52 s\n",
        "Wall time: 4.52 s\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Data format:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_sents[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "[('Melbourne', 'NP', 'B-LOC'),\n",
        " ('(', 'Fpa', 'O'),\n",
        " ('Australia', 'NP', 'B-LOC'),\n",
        " (')', 'Fpt', 'O'),\n",
        " (',', 'Fc', 'O'),\n",
        " ('25', 'Z', 'O'),\n",
        " ('may', 'NC', 'O'),\n",
        " ('(', 'Fpa', 'O'),\n",
        " ('EFE', 'NC', 'B-ORG'),\n",
        " (')', 'Fpt', 'O'),\n",
        " ('.', 'Fp', 'O')]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Features\n",
      "\n",
      "Next, define some features. In this example we use word identity, word suffix, word shape and word POS tag; also, some information from nearby words is used. \n",
      "\n",
      "This makes a simple baseline, but you certainly can add and remove some features to get (much?) better results - experiment with it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def word2features(sent, i):\n",
      "    word = sent[i][0]\n",
      "    postag = sent[i][1]\n",
      "    features = [\n",
      "        'bias',\n",
      "        'word.lower=' + word.lower(),\n",
      "        'word[-3:]=' + word[-3:],\n",
      "        'word[-2:]=' + word[-2:],\n",
      "        'word.isupper=%s' % word.isupper(),\n",
      "        'word.istitle=%s' % word.istitle(),\n",
      "        'word.isdigit=%s' % word.isdigit(),\n",
      "        'postag=' + postag,\n",
      "        'postag[:2]=' + postag[:2],\n",
      "    ]\n",
      "    if i > 0:\n",
      "        word1 = sent[i-1][0]\n",
      "        postag1 = sent[i-1][1]\n",
      "        features.extend([\n",
      "            '-1:word.lower=' + word1.lower(),\n",
      "            '-1:word.istitle=%s' % word1.istitle(),\n",
      "            '-1:word.isupper=%s' % word1.isupper(),\n",
      "            '-1:postag=' + postag1,\n",
      "            '-1:postag[:2]=' + postag1[:2],\n",
      "        ])\n",
      "    else:\n",
      "        features.append('BOS')\n",
      "        \n",
      "    if i < len(sent)-1:\n",
      "        word1 = sent[i+1][0]\n",
      "        postag1 = sent[i+1][1]\n",
      "        features.extend([\n",
      "            '+1:word.lower=' + word1.lower(),\n",
      "            '+1:word.istitle=%s' % word1.istitle(),\n",
      "            '+1:word.isupper=%s' % word1.isupper(),\n",
      "            '+1:postag=' + postag1,\n",
      "            '+1:postag[:2]=' + postag1[:2],\n",
      "        ])\n",
      "    else:\n",
      "        features.append('EOS')\n",
      "                \n",
      "    return features\n",
      "\n",
      "\n",
      "def sent2features(sent):\n",
      "    return [word2features(sent, i) for i in range(len(sent))]\n",
      "\n",
      "def sent2labels(sent):\n",
      "    return [label for token, postag, label in sent]\n",
      "\n",
      "def sent2tokens(sent):\n",
      "    return [token for token, postag, label in sent]    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is what word2features extracts:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sent2features(train_sents[0])[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "['bias',\n",
        " 'word.lower=melbourne',\n",
        " 'word[-3:]=rne',\n",
        " 'word[-2:]=ne',\n",
        " 'word.isupper=False',\n",
        " 'word.istitle=True',\n",
        " 'word.isdigit=False',\n",
        " 'postag=NP',\n",
        " 'postag[:2]=NP',\n",
        " 'BOS',\n",
        " '+1:word.lower=(',\n",
        " '+1:word.istitle=False',\n",
        " '+1:word.isupper=False',\n",
        " '+1:postag=Fpa',\n",
        " '+1:postag[:2]=Fp']"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Extract the features from the data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "X_train = [sent2features(s) for s in train_sents]\n",
      "y_train = [sent2labels(s) for s in train_sents]\n",
      "\n",
      "X_test = [sent2features(s) for s in test_sents]\n",
      "y_test = [sent2labels(s) for s in test_sents]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 3.83 s, sys: 343 ms, total: 4.17 s\n",
        "Wall time: 4.17 s\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Train the model\n",
      "\n",
      "To train the model, we create pycrfsuite.Trainer, load the training data and call 'train' method. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# use elastic net regulatization; c2 is non-zero by default\n",
      "trainer = pycrfsuite.Trainer('lbfgs', c1=1, max_iterations=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load training data to CRFsuite:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "for xseq, yseq in zip(X_train, y_train):\n",
      "    trainer.append_stringlists(xseq, yseq)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 4.62 s, sys: 76.5 ms, total: 4.69 s\n",
        "Wall time: 4.69 s\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Train the model:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "trainer.train('conll2002-esp.crfsuite')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 42.5 s, sys: 152 ms, total: 42.7 s\n",
        "Wall time: 42.7 s\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "trainer.train saves model to a file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls -lh ./conll2002-esp.crfsuite"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-rw-r--r--  1 kmike  staff   510K 30 \u0430\u043f\u0440 05:18 ./conll2002-esp.crfsuite\r\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Make predictions\n",
      "\n",
      "To use the trained model, create pycrfsuite.Tagger, open the model and use \"tag\" method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tagger = pycrfsuite.Tagger()\n",
      "tagger.open('conll2002-esp.crfsuite')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "<contextlib.closing at 0x1067dda20>"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A quick check - labels should be our IOB tags:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tagger.labels()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "['B-LOC', 'O', 'B-ORG', 'B-PER', 'I-PER', 'B-MISC', 'I-ORG', 'I-LOC', 'I-MISC']"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's tag a sentence to see how it works:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "example_sent = test_sents[0]\n",
      "print(' '.join(sent2tokens(example_sent)), end='\\n\\n')\n",
      "\n",
      "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
      "print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "La Coru\u00f1a , 23 may ( EFECOM ) .\n",
        "\n",
        "Predicted: B-LOC I-LOC O O O O B-ORG O O\n",
        "Correct:   B-LOC I-LOC O O O O B-ORG O O\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Evaluate the model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def bio_classification_report(y_true, y_pred):\n",
      "    \"\"\"\n",
      "    Classification report for a list of BIO-encoded sequences.\n",
      "    It computes token-level metrics and discards \"O\" labels.\n",
      "    \"\"\"    \n",
      "    lb = LabelBinarizer()\n",
      "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
      "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
      "        \n",
      "    tagset = set(lb.classes_) - {'O'}\n",
      "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
      "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
      "    \n",
      "    return classification_report(\n",
      "        y_true_combined,\n",
      "        y_pred_combined,\n",
      "        labels = [class_indices[cls] for cls in tagset],\n",
      "        target_names = tagset,\n",
      "    )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Predict entity labels for all sentences in our testing set ('testb' Spanish data):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "y_pred = [tagger.tag(xseq) for xseq in X_test]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 650 ms, sys: 22.1 ms, total: 672 ms\n",
        "Wall time: 672 ms\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "..and check the result. Note this report is not comparable to results in CONLL2002 papers because here we check per-token results (not per-entity). Per-entity numbers will be worse.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(bio_classification_report(y_test, y_pred))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "      B-LOC       0.75      0.74      0.74      1084\n",
        "      I-LOC       0.86      0.93      0.90       634\n",
        "     B-MISC       0.67      0.41      0.51       339\n",
        "     I-MISC       0.86      0.93      0.90       634\n",
        "      B-ORG       0.79      0.87      0.83       735\n",
        "      I-ORG       0.86      0.93      0.90       634\n",
        "      B-PER       0.59      0.51      0.55       557\n",
        "      I-PER       0.86      0.93      0.90       634\n",
        "\n",
        "avg / total       0.79      0.80      0.79      5251\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## What to do next\n",
      "\n",
      "1. Load 'testa' Spanish data.\n",
      "2. Use it to develop better features and to find best model parameters.\n",
      "3. Apply the model to 'testb' data again."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}